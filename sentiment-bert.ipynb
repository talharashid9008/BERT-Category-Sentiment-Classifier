{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10135687,"sourceType":"datasetVersion","datasetId":6255399},{"sourceId":10136720,"sourceType":"datasetVersion","datasetId":6256121},{"sourceId":10161140,"sourceType":"datasetVersion","datasetId":6274432}],"dockerImageVersionId":30806,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ****Sentiment Analysis/Rating****","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n\n# Step 1: Load the dataset\n# Assuming your dataset has two columns: 'Comments' and 'Rating'\ndf = pd.read_csv(\"/kaggle/input/charity-reviews-extended/charity_comments_dataset_large.csv\")  # Replace with your actual dataset path\n\n# Step 2: Preprocess and tokenize the data\n# Load the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Tokenizing the text data\ndef tokenize_function(examples):\n    return tokenizer(examples['Review'], padding='max_length', truncation=True, max_length=128)\n\n# Rename columns to match the format expected by the dataset\ndf = df.rename(columns={\"Comment\": \"Review\"})\ndf['Rating'] = df['Rating'] - 1\n# df.head()\n# Split the dataset into training and testing (80-20 split)\ntrain_data, val_data = train_test_split(df, test_size=0.2)\n\n# Tokenize the dataset using the tokenizer function\ntrain_encodings = tokenizer(list(train_data['Review']), truncation=True, padding=True, max_length=128)\nval_encodings = tokenizer(list(val_data['Review']), truncation=True, padding=True, max_length=128)\n\n# Convert the ratings to tensor format\ntrain_labels = torch.tensor(list(train_data['Rating']))\nval_labels = torch.tensor(list(val_data['Rating']))\n\n# Step 3: Create a custom Dataset class for PyTorch\nclass CharityReviewDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset = CharityReviewDataset(train_encodings, train_labels)\nval_dataset = CharityReviewDataset(val_encodings, val_labels)\n\n# Step 4: Initialize the BERT model for classification\nmodel = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=5)\n\n# Step 5: Set up training arguments\ntraining_args = TrainingArguments(\n    output_dir='./sentiment_results',              # Output directory for the model checkpoints\n    evaluation_strategy=\"epoch\",         # Evaluate after each epoch\n    per_device_train_batch_size=8,       # Batch size for training\n    per_device_eval_batch_size=8,        # Batch size for evaluation\n    num_train_epochs=3,                  # Number of training epochs\n    weight_decay=0.01,                   # Weight decay strength\n    logging_dir='./sentiment_logs',                # Directory for logs\n    logging_steps=10,                    # Logging frequency\n)\n\n# Step 6: Initialize Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n)\n\n# Step 7: Train the model\ntrainer.train()\n\n# Step 8: Evaluate the model\neval_results = trainer.evaluate()\nprint(f\"Evaluation results: {eval_results}\")\n\n# Step 9: Save the model\nmodel.save_pretrained('./sentiment_charity_review_model')\ntokenizer.save_pretrained('./sentiment_charity_review_model')\n\n#7b084bd9b24acdf199fcd590a4235f52abad2a1c","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:35:58.749513Z","iopub.execute_input":"2024-12-10T16:35:58.750221Z","iopub.status.idle":"2024-12-10T16:57:27.635393Z","shell.execute_reply.started":"2024-12-10T16:35:58.750188Z","shell.execute_reply":"2024-12-10T16:57:27.634708Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65cff8f4146748debf7793a91f2b52c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f596cce8d2844ac8a82d26dc61e6e092"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e47178294b9a4ba18ef28dc8269be2f0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71a8e899e9c747728f596e548d2b071e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1fcd27896934adda038965ae46dce7e"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.18.7"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241210_164956-az1olx61</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/siara-uav-lab-nuces/huggingface/runs/az1olx61' target=\"_blank\">./sentiment_results</a></strong> to <a href='https://wandb.ai/siara-uav-lab-nuces/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/siara-uav-lab-nuces/huggingface' target=\"_blank\">https://wandb.ai/siara-uav-lab-nuces/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/siara-uav-lab-nuces/huggingface/runs/az1olx61' target=\"_blank\">https://wandb.ai/siara-uav-lab-nuces/huggingface/runs/az1olx61</a>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2250' max='2250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2250/2250 07:13, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000300</td>\n      <td>0.000208</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000100</td>\n      <td>0.000101</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000100</td>\n      <td>0.000080</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='188' max='188' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [188/188 00:11]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 8.043373964028433e-05, 'eval_runtime': 11.5781, 'eval_samples_per_second': 259.11, 'eval_steps_per_second': 16.238, 'epoch': 3.0}\n","output_type":"stream"},{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"('./sentiment_charity_review_model/tokenizer_config.json',\n './sentiment_charity_review_model/special_tokens_map.json',\n './sentiment_charity_review_model/vocab.txt',\n './sentiment_charity_review_model/added_tokens.json')"},"metadata":{}}],"execution_count":1},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\n# Load the model and tokenizer from the saved directory\nmodel = BertForSequenceClassification.from_pretrained('./sentiment_charity_review_model')\ntokenizer = BertTokenizer.from_pretrained('./sentiment_charity_review_model')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:58:08.214240Z","iopub.execute_input":"2024-12-10T16:58:08.214622Z","iopub.status.idle":"2024-12-10T16:58:08.317931Z","shell.execute_reply.started":"2024-12-10T16:58:08.214557Z","shell.execute_reply":"2024-12-10T16:58:08.317247Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, max_length=128):\n    # Tokenize the text\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n    \n    # Run the model to get predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n    # Convert logits to predicted label\n    prediction = torch.argmax(logits, dim=-1).item()  # Get the class with the highest score\n    return prediction\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:58:14.966188Z","iopub.execute_input":"2024-12-10T16:58:14.966885Z","iopub.status.idle":"2024-12-10T16:58:14.972680Z","shell.execute_reply.started":"2024-12-10T16:58:14.966850Z","shell.execute_reply":"2024-12-10T16:58:14.971879Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Example review\nreview = \"i was with the performance\"\n\n# Predict the rating\npredicted_rating = predict_sentiment(review, model, tokenizer)\nprint(f\"The predicted rating for the review is: {predicted_rating + 1}\")  # Adding 1 to get the original rating (1-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T16:58:22.336881Z","iopub.execute_input":"2024-12-10T16:58:22.337207Z","iopub.status.idle":"2024-12-10T16:58:22.710990Z","shell.execute_reply.started":"2024-12-10T16:58:22.337181Z","shell.execute_reply":"2024-12-10T16:58:22.709425Z"}},"outputs":[{"name":"stdout","text":"The predicted rating for the review is: 2\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"# ****Review Classification(General/Charity)****","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Load the two CSV files\ncharity = pd.read_csv('/kaggle/input/charity-reviews-extended/charity_comments_dataset_large.csv')  # Replace with your actual file paths\ngeneral = pd.read_csv('/kaggle/input/amazon-reviews/train.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:01.183477Z","iopub.execute_input":"2024-12-11T04:44:01.183883Z","iopub.status.idle":"2024-12-11T04:44:36.001656Z","shell.execute_reply.started":"2024-12-11T04:44:01.183851Z","shell.execute_reply":"2024-12-11T04:44:36.000812Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"general.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:40.801451Z","iopub.execute_input":"2024-12-11T04:44:40.802291Z","iopub.status.idle":"2024-12-11T04:44:40.820815Z","shell.execute_reply.started":"2024-12-11T04:44:40.802245Z","shell.execute_reply":"2024-12-11T04:44:40.819834Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   2                     Stuning even for the non-gamer  \\\n0  2              The best soundtrack ever to anything.   \n1  2                                           Amazing!   \n2  2                               Excellent Soundtrack   \n3  2  Remember, Pull Your Jaw Off The Floor After He...   \n4  2                            an absolute masterpiece   \n\n  This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^  \n0  I'm reading a lot of reviews saying that this ...                                                                                                                                                                                                                                                                                                                                                          \n1  This soundtrack is my favorite music of all ti...                                                                                                                                                                                                                                                                                                                                                          \n2  I truly like this soundtrack and I enjoy video...                                                                                                                                                                                                                                                                                                                                                          \n3  If you've played the game, you know how divine...                                                                                                                                                                                                                                                                                                                                                          \n4  I am quite sure any of you actually taking the...                                                                                                                                                                                                                                                                                                                                                          ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>2</th>\n      <th>Stuning even for the non-gamer</th>\n      <th>This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>The best soundtrack ever to anything.</td>\n      <td>I'm reading a lot of reviews saying that this ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>Amazing!</td>\n      <td>This soundtrack is my favorite music of all ti...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Excellent Soundtrack</td>\n      <td>I truly like this soundtrack and I enjoy video...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n      <td>If you've played the game, you know how divine...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>an absolute masterpiece</td>\n      <td>I am quite sure any of you actually taking the...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"general.rename(columns={ 'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^': 'Review'}, inplace=True)\n# Dropping both '2' and 'Great CD' columns\ngeneral = general.drop(['2', 'Stuning even for the non-gamer'], axis=1)\ngeneral[\"label\"]=0\n# Confirming the columns are dropped\nprint(general.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:44.854956Z","iopub.execute_input":"2024-12-11T04:44:44.855329Z","iopub.status.idle":"2024-12-11T04:44:44.986674Z","shell.execute_reply.started":"2024-12-11T04:44:44.855295Z","shell.execute_reply":"2024-12-11T04:44:44.985491Z"}},"outputs":[{"name":"stdout","text":"Index(['Review', 'label'], dtype='object')\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"charity.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:48.036866Z","iopub.execute_input":"2024-12-11T04:44:48.037315Z","iopub.status.idle":"2024-12-11T04:44:48.048952Z","shell.execute_reply.started":"2024-12-11T04:44:48.037276Z","shell.execute_reply":"2024-12-11T04:44:48.047827Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Rating\n0  This organization seems like a scam. I hope th...       1\n1                     The volunteers were very rude.       1\n2  No transparency in how funds are utilized. Suc...       1\n3  The volunteers were very rude. I hope they con...       1\n4               This organization seems like a scam.       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>This organization seems like a scam. I hope th...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>The volunteers were very rude.</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>No transparency in how funds are utilized. Suc...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>The volunteers were very rude. I hope they con...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>This organization seems like a scam.</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"charity.rename(columns={ 'Comment': 'Review'}, inplace=True)\n# Dropping both '2' and 'Great CD' columns\ncharity = charity.drop(['Rating'], axis=1)\ncharity[\"label\"]=1\n# Confirming the columns are dropped\nprint(charity.columns)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:52.629711Z","iopub.execute_input":"2024-12-11T04:44:52.630054Z","iopub.status.idle":"2024-12-11T04:44:52.638845Z","shell.execute_reply.started":"2024-12-11T04:44:52.630023Z","shell.execute_reply":"2024-12-11T04:44:52.637915Z"}},"outputs":[{"name":"stdout","text":"Index(['Review', 'label'], dtype='object')\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"print(len(charity))\nprint(len(general))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:44:56.440539Z","iopub.execute_input":"2024-12-11T04:44:56.440890Z","iopub.status.idle":"2024-12-11T04:44:56.446149Z","shell.execute_reply.started":"2024-12-11T04:44:56.440860Z","shell.execute_reply":"2024-12-11T04:44:56.445243Z"}},"outputs":[{"name":"stdout","text":"15000\n3599999\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"general = general.head(len(charity))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:45:02.878256Z","iopub.execute_input":"2024-12-11T04:45:02.878613Z","iopub.status.idle":"2024-12-11T04:45:02.883330Z","shell.execute_reply.started":"2024-12-11T04:45:02.878583Z","shell.execute_reply":"2024-12-11T04:45:02.882294Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"print(len(charity))\nprint(len(general))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:45:06.203007Z","iopub.execute_input":"2024-12-11T04:45:06.203849Z","iopub.status.idle":"2024-12-11T04:45:06.208810Z","shell.execute_reply.started":"2024-12-11T04:45:06.203812Z","shell.execute_reply":"2024-12-11T04:45:06.207773Z"}},"outputs":[{"name":"stdout","text":"15000\n15000\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"combined_reviews = pd.concat([charity[['Review', 'label']], general[['Review', 'label']]], axis=0).reset_index(drop=True)\n\n# Print the first few rows of the combined DataFrame\nprint(combined_reviews.head())\nprint(len(combined_reviews))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T04:45:10.540917Z","iopub.execute_input":"2024-12-11T04:45:10.541607Z","iopub.status.idle":"2024-12-11T04:45:10.556274Z","shell.execute_reply.started":"2024-12-11T04:45:10.541570Z","shell.execute_reply":"2024-12-11T04:45:10.555167Z"}},"outputs":[{"name":"stdout","text":"                                              Review  label\n0  This organization seems like a scam. I hope th...      1\n1                     The volunteers were very rude.      1\n2  No transparency in how funds are utilized. Suc...      1\n3  The volunteers were very rude. I hope they con...      1\n4               This organization seems like a scam.      1\n30000\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom sklearn.model_selection import train_test_split\nfrom transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n\n# Step 1: Split the dataset into training and testing (80-20 split)\n# Assuming 'combined_reviews' is the DataFrame containing your reviews and labels\ntrain_data, val_data = train_test_split(combined_reviews, test_size=0.2)\n\n# Step 2: Preprocess and tokenize the data\n# Load the BERT tokenizer\ntokenizer_new = BertTokenizer.from_pretrained('bert-base-uncased')\n\n# Tokenizing function\ndef tokenize_function_new(examples):\n    return tokenizer_new(examples['Review'], padding='max_length', truncation=True, max_length=128)\n\n# Tokenize the dataset\ntrain_encodings_new = tokenizer_new(list(train_data['Review']), truncation=True, padding=True, max_length=128)\nval_encodings_new = tokenizer_new(list(val_data['Review']), truncation=True, padding=True, max_length=128)\n\n# Convert the labels to tensor format\ntrain_labels_new = torch.tensor(list(train_data['label']))\nval_labels_new = torch.tensor(list(val_data['label']))\n\n# Step 3: Create a custom Dataset class for PyTorch\nclass ReviewDatasetNew(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item['labels'] = self.labels[idx]\n        return item\n\n    def __len__(self):\n        return len(self.labels)\n\ntrain_dataset_new = ReviewDatasetNew(train_encodings_new, train_labels_new)\nval_dataset_new = ReviewDatasetNew(val_encodings_new, val_labels_new)\n\n# Step 4: Initialize the BERT model for binary classification (2 labels: 0 and 1)\nmodel_new = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n\n# Step 5: Set up training arguments\ntraining_args_new = TrainingArguments(\n    output_dir='./Category_new_results',              # Output directory for the model checkpoints\n    evaluation_strategy=\"epoch\",             # Evaluate after each epoch\n    per_device_train_batch_size=8,           # Batch size for training\n    per_device_eval_batch_size=8,            # Batch size for evaluation\n    num_train_epochs=4,                      # Number of training epochs\n    weight_decay=0.01,                       # Weight decay strength\n    # logging_dir='./Category_new_logs',                # Directory for logs\n    logging_steps=10,                        # Logging frequency\n)\n\n# Step 6: Initialize the Trainer\ntrainer_new = Trainer(\n    model=model_new,\n    args=training_args_new,\n    train_dataset=train_dataset_new,\n    eval_dataset=val_dataset_new,\n)\n\n# Step 7: Train the model\ntrainer_new.train()\n\n# Step 8: Evaluate the model\neval_results_new = trainer_new.evaluate()\nprint(f\"Evaluation results: {eval_results_new}\")\n\n# Step 9: Save the model and tokenizer\nmodel_new.save_pretrained('./Category_new_charity_review_model')\ntokenizer_new.save_pretrained('./Category_new_charity_review_model')\n\n# Optionally, you can also save the evaluation results in a file\n# eval_results_df_new = pd.DataFrame([eval_results_new])\n# eval_results_df_new.to_csv('./new_evaluation_results.csv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:00:28.434713Z","iopub.execute_input":"2024-12-11T05:00:28.435080Z","iopub.status.idle":"2024-12-11T05:33:16.579561Z","shell.execute_reply.started":"2024-12-11T05:00:28.435048Z","shell.execute_reply":"2024-12-11T05:33:16.578696Z"}},"outputs":[{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='6000' max='6000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [6000/6000 31:45, Epoch 4/4]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.000000</td>\n      <td>0.000010</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.000000</td>\n      <td>0.000008</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.000000</td>\n      <td>0.000007</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.000000</td>\n      <td>0.000001</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"name":"stdout","text":"Evaluation results: {'eval_loss': 7.532453878411616e-07, 'eval_runtime': 32.736, 'eval_samples_per_second': 183.284, 'eval_steps_per_second': 11.455, 'epoch': 4.0}\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"('./Category_new_charity_review_model/tokenizer_config.json',\n './Category_new_charity_review_model/special_tokens_map.json',\n './Category_new_charity_review_model/vocab.txt',\n './Category_new_charity_review_model/added_tokens.json')"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"# Tokenize the test data\ntest_encodings_new = tokenizer_new(list(val_data['Review']), truncation=True, padding=True, max_length=128)\n\n# Convert the labels to tensor format for test data\ntest_labels_new = torch.tensor(list(val_data['label']))\n\n# Create a dataset for the test data\ntest_dataset_new = ReviewDatasetNew(test_encodings_new, test_labels_new)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:39:07.993460Z","iopub.execute_input":"2024-12-11T05:39:07.993848Z","iopub.status.idle":"2024-12-11T05:39:14.077156Z","shell.execute_reply.started":"2024-12-11T05:39:07.993814Z","shell.execute_reply":"2024-12-11T05:39:14.076221Z"}},"outputs":[],"execution_count":28},{"cell_type":"code","source":"# Perform prediction on the test data\ntest_results_new = trainer_new.predict(test_dataset_new)\n\n# test_results_new.predictions contains the logits from the model\n# Apply softmax to convert logits to probabilities and get predicted labels\npredicted_labels_new = torch.argmax(torch.tensor(test_results_new.predictions), dim=1)\n\n# Print predicted labels and actual labels\nprint(f\"Predicted labels: {predicted_labels_new}\")\nprint(f\"Actual labels: {test_labels_new}\")\n\n# If you want to see the test metrics (accuracy, loss, etc.)\nprint(f\"Test metrics: {test_results_new.metrics}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:40:09.359312Z","iopub.execute_input":"2024-12-11T05:40:09.359719Z","iopub.status.idle":"2024-12-11T05:40:42.739038Z","shell.execute_reply.started":"2024-12-11T05:40:09.359687Z","shell.execute_reply":"2024-12-11T05:40:42.738191Z"}},"outputs":[{"name":"stdout","text":"Predicted labels: tensor([1, 0, 0,  ..., 0, 0, 0])\nActual labels: tensor([1, 0, 0,  ..., 0, 0, 0])\nTest metrics: {'test_loss': 7.532453878411616e-07, 'test_runtime': 33.3594, 'test_samples_per_second': 179.859, 'test_steps_per_second': 11.241}\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\n# Calculate accuracy\naccuracy_new = accuracy_score(test_labels_new.numpy(), predicted_labels_new.numpy())\nprint(f\"Test Accuracy: {accuracy_new}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:41:39.465949Z","iopub.execute_input":"2024-12-11T05:41:39.466916Z","iopub.status.idle":"2024-12-11T05:41:39.482449Z","shell.execute_reply.started":"2024-12-11T05:41:39.466878Z","shell.execute_reply":"2024-12-11T05:41:39.481189Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 1.0\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"# Predicting Review Category","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\n# Load the model and tokenizer from the saved directory\nmodel_category = BertForSequenceClassification.from_pretrained('./Category_new_charity_review_model')\ntokenizer_category = BertTokenizer.from_pretrained('./Category_new_charity_review_model')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:15:20.624906Z","iopub.execute_input":"2024-12-10T08:15:20.625229Z","iopub.status.idle":"2024-12-10T08:15:37.483724Z","shell.execute_reply.started":"2024-12-10T08:15:20.625199Z","shell.execute_reply":"2024-12-10T08:15:37.482778Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def predict_category(text, model, tokenizer, max_length=128):\n    # Tokenize the text\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n    \n    # Run the model to get predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n    # Convert logits to predicted label\n    prediction = torch.argmax(logits, dim=-1).item()  # Get the class with the highest score\n    return prediction\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:15:43.660814Z","iopub.execute_input":"2024-12-10T08:15:43.661403Z","iopub.status.idle":"2024-12-10T08:15:43.666772Z","shell.execute_reply.started":"2024-12-10T08:15:43.661369Z","shell.execute_reply":"2024-12-10T08:15:43.665910Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Example review\nlabels = ['General','Charity']\nreview = \"He is a good sports man\"\n\n# Predict the rating\npredicted_category = predict_category(review, model_category, tokenizer_category)\nprint(f\"The review is: {labels[predicted_category]}\")  # Adding 1 to get the original rating (1-5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-10T08:20:10.491054Z","iopub.execute_input":"2024-12-10T08:20:10.491387Z","iopub.status.idle":"2024-12-10T08:20:10.637658Z","shell.execute_reply.started":"2024-12-10T08:20:10.491357Z","shell.execute_reply":"2024-12-10T08:20:10.636669Z"}},"outputs":[{"name":"stdout","text":"The review is: Charity\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import shutil\n\n# Path to the charity_review_model folder\nmodel_folder = './sentiment_charity_review_model'  # Replace with your actual folder path\nzip_filename = 'sentiment_charity_review_model.zip'  # Name of the zip file to be created\n\n# Create a zip archive of the charity_review_model folder\nshutil.make_archive('sentiment_charity_review_model', 'zip', model_folder)\n\nprint(f\"Model folder has been zipped as {zip_filename}.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T11:40:57.210492Z","iopub.execute_input":"2024-12-11T11:40:57.211201Z","iopub.status.idle":"2024-12-11T11:41:19.546173Z","shell.execute_reply.started":"2024-12-11T11:40:57.211166Z","shell.execute_reply":"2024-12-11T11:41:19.545254Z"}},"outputs":[{"name":"stdout","text":"Model folder has been zipped as sentiment_charity_review_model.zip.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"def predict_sentiment(text, model, tokenizer, max_length=128):\n    # Tokenize the text\n    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding='max_length', max_length=max_length)\n    \n    # Run the model to get predictions\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        \n    # Convert logits to predicted label\n    prediction = torch.argmax(logits, dim=-1).item()  # Get the class with the highest score\n    return prediction\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:11:09.339251Z","iopub.execute_input":"2024-12-11T07:11:09.339697Z","iopub.status.idle":"2024-12-11T07:11:09.346095Z","shell.execute_reply.started":"2024-12-11T07:11:09.339657Z","shell.execute_reply":"2024-12-11T07:11:09.344947Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\nimport torch\n\nreview = \"That donation helped a lot of students\"\n\ncategory_model = BertForSequenceClassification.from_pretrained('./Category_new_charity_review_model')\ncategory_tokenizer = BertTokenizer.from_pretrained('./Category_new_charity_review_model')\n\nrating_model = BertForSequenceClassification.from_pretrained('./sentiment_charity_review_model')\nrating_tokenizer = BertTokenizer.from_pretrained('./sentiment_charity_review_model')\n\npredicted_category = predict_sentiment(review, category_model, category_tokenizer)\nif(predicted_category):\n    predicted_review = predict_sentiment(review, rating_model, rating_tokenizer)  \n    print(\"Rating: \", predicted_review)\nelse:\n    print(\"This is a general review\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T07:11:39.951784Z","iopub.execute_input":"2024-12-11T07:11:39.952167Z","iopub.status.idle":"2024-12-11T07:11:40.877472Z","shell.execute_reply.started":"2024-12-11T07:11:39.952135Z","shell.execute_reply":"2024-12-11T07:11:40.876337Z"}},"outputs":[{"name":"stdout","text":"Rating:  4\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import shutil\n\n# Path to the folder you want to delete\nfolder_path = '/kaggle/working/Category_new_results'  # replace with the actual folder path\n\n# Delete the folder and its contents\nshutil.rmtree(folder_path)\n\nprint(f\"Deleted folder: {folder_path}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:00:18.441095Z","iopub.execute_input":"2024-12-11T05:00:18.441485Z","iopub.status.idle":"2024-12-11T05:00:19.309598Z","shell.execute_reply.started":"2024-12-11T05:00:18.441450Z","shell.execute_reply":"2024-12-11T05:00:19.308670Z"}},"outputs":[{"name":"stdout","text":"Deleted folder: /kaggle/working/Category_new_results\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import os\n\n# Specify the path to the zip file you want to remove\nzip_file_path = '/kaggle/working/new_evaluation_results.csv'  # replace with the actual file path\n\n# Remove the zip file\nif os.path.exists(zip_file_path):\n    os.remove(zip_file_path)\n    print(f\"{zip_file_path} has been deleted.\")\nelse:\n    print(f\"{zip_file_path} does not exist.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T05:00:03.414352Z","iopub.execute_input":"2024-12-11T05:00:03.415141Z","iopub.status.idle":"2024-12-11T05:00:03.453228Z","shell.execute_reply.started":"2024-12-11T05:00:03.415102Z","shell.execute_reply":"2024-12-11T05:00:03.452043Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Remove the zip file\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(zip_file_path):\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzip_file_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzip_file_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has been deleted.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/Category_new_results'"],"ename":"IsADirectoryError","evalue":"[Errno 21] Is a directory: '/kaggle/working/Category_new_results'","output_type":"error"}],"execution_count":25}]}